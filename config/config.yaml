# arXiv Scraper Configuration

# OCR Processing Settings
ocr:
  # Primary OCR model to use
  model: "mistral_ocr"  # Options: mistral_ocr, nougat, unstructured, surya
  
  # Device settings
  device: "cuda"  # Options: cuda, cpu, mps
  
  # Batch processing
  batch_size: 4
  
  # Fallback models in order of preference
  fallback_models:
    - "nougat"
    - "unstructured"
    - "surya"
  
  # OCR specific settings
  mistral_ocr:
    max_length: 2048
    temperature: 0.1
  
  nougat:
    model_size: "base"  # Options: base, small
    recompute: false
  
  unstructured:
    strategy: "hi_res"  # Options: hi_res, fast, ocr_only
    model_name: "yolox"
  
  surya:
    batch_size: 2
    det_batch_size: 2

# Text Processing Settings
text_processing:
  # Reference removal settings
  remove_references: true
  
  # Reference section detection patterns
  reference_patterns:
    - "REFERENCES"
    - "References"
    - "BIBLIOGRAPHY"
    - "Bibliography"
    - "参考文献"
    - "文献"
    - "Literature Cited"
    - "LITERATURE CITED"
  
  # Citation patterns to clean from main text
  citation_patterns:
    - r"\[(\d+(?:[-–,]\s*\d+)*)\]"  # [1], [1-3], [1,2,3]
    - r"\(([A-Za-z]+\s+(?:et\s+al\.?\s*)?(?:19|20)\d{2}[a-z]?(?:;\s*[A-Za-z]+\s+(?:et\s+al\.?\s*)?(?:19|20)\d{2}[a-z]?)*)\)"  # (Author 2023)
    - r"\((?:19|20)\d{2}[a-z]?\)"  # (2023)
  
  # Text cleanup settings
  citation_cleanup: true
  remove_page_numbers: true
  remove_headers_footers: true
  normalize_whitespace: true
  
  # Quality thresholds
  min_text_length: 1000  # Minimum text length after processing
  max_reference_ratio: 0.3  # Maximum ratio of references to total text

# LLM Processing Settings
llm:
  # Primary LLM model
  model: "gpt-4"  # Options: gpt-4, gpt-3.5-turbo, claude-3-opus, claude-3-sonnet
  
  # Generation parameters
  temperature: 0.1
  max_tokens: 2000
  top_p: 1.0
  frequency_penalty: 0.0
  presence_penalty: 0.0
  
  # Retry settings
  max_retries: 3
  retry_delay: 1.0
  
  # Fallback models
  fallback_models:
    - "gpt-3.5-turbo"
    - "claude-3-sonnet"
  
  # API settings
  openai:
    api_key: null  # Set via environment variable OPENAI_API_KEY
    organization: null
    
  anthropic:
    api_key: null  # Set via environment variable ANTHROPIC_API_KEY

# Extraction Target Items
extraction_items:
  - name: "手法の肝"
    description: "論文の核となる技術手法・アプローチ"
    max_length: 500
    
  - name: "制限事項"
    description: "手法の限界や制約条件"
    max_length: 500
    
  - name: "対象ナレッジ"
    description: "扱う知識領域・データ種別"
    max_length: 500
    
  - name: "URL"
    description: "arXiv論文のURL"
    max_length: 200
    
  - name: "タイトル"
    description: "論文タイトル"
    max_length: 300
    
  - name: "出版年"
    description: "発表年"
    max_length: 50
    
  - name: "研究分野"
    description: "分野分類"
    max_length: 200
    
  - name: "課題設定"
    description: "解決しようとする問題"
    max_length: 500
    
  - name: "論文の主張"
    description: "主要な貢献・結論"
    max_length: 500

# Output Settings
output:
  # File format
  format: "csv"  # Options: csv, json, xlsx
  
  # CSV settings
  csv:
    encoding: "utf-8"
    delimiter: ","
    quotechar: '"'
    quoting: "minimal"  # Options: minimal, all, non_numeric, none
    
  # JSON settings  
  json:
    indent: 2
    ensure_ascii: false
    
  # Default values for missing data
  default_values:
    missing_data: "N/A"
    error_data: "ERROR"
    
  # Output directory
  output_dir: "./output"
  
  # Filename patterns
  filename_patterns:
    single: "arxiv_extraction_{timestamp}.csv"
    batch: "arxiv_batch_{timestamp}.csv"

# Logging Settings
logging:
  level: "INFO"  # Options: DEBUG, INFO, WARNING, ERROR, CRITICAL
  
  # Log file settings
  file:
    enabled: true
    path: "./logs/arxiv_scraper.log"
    max_size: "10MB"
    backup_count: 5
    
  # Console logging
  console:
    enabled: true
    format: "{time:YYYY-MM-DD HH:mm:ss} | {level: <8} | {name}:{function}:{line} - {message}"
    
  # Component-specific logging
  components:
    ocr: "INFO"
    reference_cleaner: "DEBUG"
    llm_extractor: "INFO"
    arxiv_api: "INFO"

# Performance Settings
performance:
  # Processing timeouts (seconds)
  timeouts:
    pdf_download: 30
    ocr_processing: 300
    reference_removal: 10
    llm_extraction: 120
    
  # Memory settings
  memory:
    max_pdf_size: "50MB"
    max_text_length: 100000
    
  # Batch processing
  batch:
    max_concurrent: 3
    chunk_size: 10
    
  # Caching
  cache:
    enabled: true
    ttl: 3600  # seconds
    max_size: 100

# arXiv API Settings
arxiv:
  # API endpoint
  base_url: "http://export.arxiv.org/api/query"
  
  # Request settings
  max_results: 1
  sort_by: "relevance"
  sort_order: "descending"
  
  # Rate limiting
  rate_limit:
    requests_per_second: 1
    burst_size: 3
    
  # PDF download settings
  pdf:
    user_agent: "arXiv-Scraper/1.0"
    timeout: 30
    max_retries: 3